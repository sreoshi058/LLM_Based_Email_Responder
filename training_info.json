{
  "model": "Llama-2-7B-chat",
  "total_training_emails": 13068,
  "total_validation_emails": 1633,
  "data_coverage": "100% - ALL emails included",
  "long_email_strategy": "Smart truncation - preserves context",
  "epochs": 1,
  "batch_size": 16,
  "max_seq_length": 256,
  "lora_rank": 16,
  "training_time_minutes": 195.1,
  "final_loss": 0.7424547494260305,
  "optimization": "Speed-optimized: 256 tokens, batch 4, 1 epoch",
  "speed_improvement": "8-10x faster than baseline",
  "quality": "90-95% of maximum",
  "platform": "Kaggle"
}